# Deep neural network that classifies previously labeled and make predictions on newly labeled data

import numpy as np
import matplotlib.pyplot as plt
import keras
from sklearn import datasets
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import Adam

np.random.seed(0)

n_pts = 500
X, y = datasets.make_circles(n_samples = n_pts, random_state = 123, noise = 0.1, factor = 0.2)


plt.scatter(X[y==0, 0],X[y==0, 1])
plt.scatter(X[y==1, 0], X[y==1, 1])

# #constructing the neural network



# The input
model = Sequential()


# defining the hidden layer
model.add(Dense(4, input_shape = (2,), activation = 'sigmoid'))


# Defining the output layer
model.add(Dense(1, activation = 'sigmoid'))


#compile the model
model.compile(Adam(lr = 0.1), 'binary_crossentropy', metrics = ['accuracy'])


#training the model
h = model.fit(x=X, y=y, verbose = 1, batch_size = 20, epochs = 100, shuffle ='true')


# plotting accuracy

plt.plot(h.history['acc'])
plt.xlabel('epoch')
plt.legend(['accuracy'])
plt.title('accuracy')


#plotting Loss

plt.plot(h.history['loss'])
plt.xlabel('epoch')
plt.legend(['loss'])
plt.title('loss')


#plots decision boundary

def plot_decision_boundary(X, y, model):
    x_span = np.linspace(min(X[:, 0]) - 0.25, max(X[:, 0]) + 0.25)
    y_span = np.linspace(min(X[:, 1]) - 0.25, max(X[:, 1]) + 0.25)
    xx, yy = np.meshgrid(x_span, y_span)
    xx_,yy_ = xx.ravel(), yy.ravel()
    grid = np.c_[xx_, yy_]
    pred_func = model.predict(grid)
    z = pred_func.reshape(xx.shape)
    plt.contourf(xx, yy, z)

plot_decision_boundary(X, y, model)
plt.scatter(X[:n_pts, 0], X[:n_pts, 1])
plt.scatter(X[n_pts:, 0], X[n_pts:, 1])

plot_decision_boundary(X, y, model)
plt.scatter(X[:n_pts, 0], X[:n_pts, 1])
plt.scatter(X[n_pts:, 0], X[n_pts:, 1])


# predict points not previosly on the model

x = 0.1
y = 0
point = np.array([[x, y]])
prediction = model.predict(point)
plt.plot([x], [y], marker='o', markersize = 10, color = 'red')
print("Prediction is", prediction)
